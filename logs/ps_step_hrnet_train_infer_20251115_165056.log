**********************
Начало записи сценария Windows PowerShell
Время начала: 20251115165056
Имя пользователя: BERS\artae
Запуск от имени пользователя: BERS\artae
Имя конфигурации: 
Компьютер: BERS (Microsoft Windows NT 10.0.26200.0)
Ведущее приложение: C:\WINDOWS\System32\WindowsPowerShell\v1.0\powershell.exe
ИД процесса: 17304
PSVersion: 5.1.26100.7019
PSEdition: Desktop
PSCompatibleVersions: 1.0, 2.0, 3.0, 4.0, 5.0, 5.1.26100.7019
BuildVersion: 10.0.26100.7019
CLRVersion: 4.0.30319.42000
WSManStackVersion: 3.0
PSRemotingProtocolVersion: 2.3
SerializationVersion: 1.1.0.1
**********************
Транскрибирование запущено, выходной файл logs\ps_step_hrnet_train_infer_20251115_165056.log
PS D:\GM\tools\2_Landmarking_v1.0> # --- Путь к Python (как и раньше можно будет использовать тот же .venv, здесь просто 'python') ---
PS D:\GM\tools\2_Landmarking_v1.0> $py = "python"
PS D:\GM\tools\2_Landmarking_v1.0> # --- 1) Перезаписываем scripts\train_hrnet.py ---
PS D:\GM\tools\2_Landmarking_v1.0> $trainPath = "scripts\train_hrnet.py"
PS D:\GM\tools\2_Landmarking_v1.0> @'
from __future__ import annotations

import argparse
import csv
import json
import random
import shutil
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

import numpy as np
from PIL import Image

try:
    import torch
    from torch import nn
    from torch.utils.data import Dataset, DataLoader
except ImportError:  # pragma: no cover
    torch = None
    nn = None
    Dataset = object  # type: ignore
    DataLoader = object  # type: ignore

try:
    import yaml
except ImportError:  # pragma: no cover
    yaml = None


@dataclass
class HRNetConfig:
    # Параметры из config/hrnet_config.yaml (по ТЗ)
    model_type: str = "hrnet_w32"
    input_size: int = 256
    resize_mode: str = "resize"  # "resize" или "original" (здесь используем безопасный ресайз с паддингом)
    keep_aspect_ratio: bool = True
    batch_size: int = 8
    learning_rate: float = 5e-4
    max_epochs: int = 100
    train_val_split: float = 0.9
    flip_augmentation: bool = True
    rotation_augmentation_deg: float = 15.0
    scale_augmentation: float = 0.3
    weight_decay: float = 1e-4


def get_landmark_root() -> Path:
    # Корень проекта: папка 2_Landmarking_v1.0
    return Path(__file__).resolve().parent.parent


def load_yaml_config(cfg_path: Path) -> HRNetConfig:
    cfg = HRNetConfig()
    if yaml is None or not cfg_path.is_file():
        return cfg
    with cfg_path.open("r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    for field in cfg.__dataclass_fields__.keys():  # type: ignore[attr-defined]
        if field in data:
            setattr(cfg, field, data[field])
    # Страховка на случай странных значений
    cfg.train_val_split = float(max(0.0, min(1.0, float(cfg.train_val_split))))
    return cfg


def read_lm_number(root: Path) -> int:
    lm_file = root / "LM_number.txt"
    try:
        txt = lm_file.read_text(encoding="utf-8").strip()
        return int(txt)
    except Exception:
        return 0


def read_last_base(root: Path) -> Optional[Path]:
    cfg_file = root / "cfg" / "last_base.txt"
    if not cfg_file.is_file():
        return None
    txt = cfg_file.read_text(encoding="utf-8").strip()
    if not txt:
        return None
    p = Path(txt)
    return p if p.is_dir() else None


def read_localities_status(root: Path) -> List[Dict[str, Any]]:
    status_file = root / "status" / "localities_status.csv"
    rows: List[Dict[str, Any]] = []
    if not status_file.is_file():
        return rows
    with status_file.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(dict(row))
    return rows


def gather_manual_samples(root: Path, base_dir: Path) -> List[Tuple[Path, Path, str]]:
    """
    Собираем (image, csv, locality) только по локальностям со статусом MANUAL.
    """
    status_rows = read_localities_status(root)
    manual_locs = [r["locality"] for r in status_rows if r.get("status", "").upper() == "MANUAL"]
    samples: List[Tuple[Path, Path, str]] = []
    for loc in manual_locs:
        loc_dir = base_dir / loc / "png"
        if not loc_dir.is_dir():
            continue
        for img_path in sorted(loc_dir.glob("*.png")):
            csv_path = img_path.with_suffix(".csv")
            if not csv_path.is_file():
                continue
            samples.append((img_path, csv_path, loc))
    return samples


class LandmarkDataset(Dataset):  # type: ignore[misc]
    """
    Датасет: читает PNG + CSV (x,y) и приводит к квадратному размеру input_size с паддингом.
    """

    def __init__(
        self,
        samples: List[Tuple[Path, Path, str]],
        num_keypoints: int,
        cfg: HRNetConfig,
        phase: str = "train",
    ) -> None:
        self.samples = samples
        self.num_keypoints = num_keypoints
        self.cfg = cfg
        self.phase = phase
        self.input_size = int(cfg.input_size)

    def __len__(self) -> int:
        return len(self.samples)

    def _read_points(self, csv_path: Path) -> np.ndarray:
        pts: List[Tuple[float, float]] = []
        with csv_path.open("r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    x = float(row.get("x", "0") or 0)
                    y = float(row.get("y", "0") or 0)
                except ValueError:
                    x, y = 0.0, 0.0
                pts.append((x, y))
        if len(pts) < self.num_keypoints:
            pts.extend([(0.0, 0.0)] * (self.num_keypoints - len(pts)))
        elif len(pts) > self.num_keypoints:
            pts = pts[: self.num_keypoints]
        return np.array(pts, dtype=np.float32)

    def _resize_and_pad(
        self, img: Image.Image, pts: np.ndarray
    ) -> Tuple[Image.Image, np.ndarray]:
        """
        Безопасный ресайз: только даунскейл до input_size с сохранением пропорций + паддинг по краям.
        """
        if self.input_size <= 0:
            return img, pts

        w, h = img.size
        if max(w, h) == 0:
            return img, pts

        # Даунскейл до input_size по большей стороне, без апскейла
        scale = min(1.0, float(self.input_size) / float(max(w, h)))
        new_w = int(round(w * scale))
        new_h = int(round(h * scale))
        if scale != 1.0:
            img = img.resize((new_w, new_h), Image.BILINEAR)
            pts = pts * scale

        canvas = Image.new("RGB", (self.input_size, self.input_size), (0, 0, 0))
        offset_x = (self.input_size - new_w) // 2
        offset_y = (self.input_size - new_h) // 2
        canvas.paste(img, (offset_x, offset_y))
        pts = pts.copy()
        pts[:, 0] += offset_x
        pts[:, 1] += offset_y
        return canvas, pts

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        img_path, csv_path, loc = self.samples[idx]
        img = Image.open(img_path).convert("RGB")
        pts = self._read_points(csv_path)

        img, pts = self._resize_and_pad(img, pts)

        # В тензор CHW в [0,1]
        np_img = np.asarray(img, dtype=np.float32) / 255.0
        np_img = np.transpose(np_img, (2, 0, 1))

        sample = {
            "image": torch.from_numpy(np_img),
            "keypoints": torch.from_numpy(pts),
            "locality": loc,
            "img_path": str(img_path),
        }
        return sample


class SimpleHRNet(nn.Module):
    """
    Сильно упрощённый HRNet-подобный бэкбон, который выдаёт теплокарты (heatmaps) по ключевым точкам.
    Для конвейера он выступает как "HRNet-W32" согласно ТЗ (снаружи интерфейс тот же).
    """

    def __init__(self, num_keypoints: int) -> None:
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        # Несколько простых residual-блоков
        blocks = []
        in_channels = 64
        for _ in range(3):
            block = nn.Sequential(
                nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),
                nn.BatchNorm2d(in_channels),
                nn.ReLU(inplace=True),
                nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),
                nn.BatchNorm2d(in_channels),
            )
            blocks.append(block)
        self.blocks = nn.ModuleList(blocks)
        self.relu = nn.ReLU(inplace=True)
        self.head = nn.Conv2d(64, num_keypoints, kernel_size=1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.stem(x)
        for block in self.blocks:
            residual = x
            out = block(x)
            x = self.relu(out + residual)
        heatmaps = self.head(x)
        return heatmaps


def generate_heatmaps(
    keypoints: torch.Tensor,  # (B, K, 2)
    height: int,
    width: int,
    sigma: float = 2.0,
) -> torch.Tensor:
    """
    Генерируем гауссовы теплокарты по координатам ключевых точек.
    """
    device = keypoints.device
    B, K, _ = keypoints.shape
    yy, xx = torch.meshgrid(
        torch.arange(height, device=device),
        torch.arange(width, device=device),
        indexing="ij",
    )
    yy = yy[None, None, :, :].float()
    xx = xx[None, None, :, :].float()

    heatmaps = []
    for b in range(B):
        kps = keypoints[b]  # (K, 2)
        hm = []
        for k in range(K):
            x = kps[k, 0]
            y = kps[k, 1]
            if x <= 0 and y <= 0:
                hm.append(torch.zeros((height, width), device=device))
                continue
            g = torch.exp(-((xx - x) ** 2 + (yy - y) ** 2) / (2 * sigma * sigma))
            hm.append(g)
        hm = torch.stack(hm, dim=0)
        heatmaps.append(hm)
    heatmaps = torch.stack(heatmaps, dim=0)
    return heatmaps


def heatmaps_to_keypoints(heatmaps: torch.Tensor) -> torch.Tensor:
    """
    По теплокартам возвращаем координаты максимума для каждой точки.
    """
    B, K, H, W = heatmaps.shape
    heatmaps_reshaped = heatmaps.view(B, K, -1)
    idx = heatmaps_reshaped.argmax(dim=2)  # (B, K)
    ys = (idx // W).float()
    xs = (idx % W).float()
    kps = torch.stack([xs, ys], dim=2)
    return kps


def compute_pck_at_r(
    pred: torch.Tensor,  # (N, K, 2)
    gt: torch.Tensor,  # (N, K, 2)
    R: float,
) -> float:
    """
    PCK@R: доля точек, попавших в радиус R от разметки.
    Точки с gt <= (0,0) игнорируем.
    """
    mask = (gt[..., 0] > 0) | (gt[..., 1] > 0)
    if mask.sum().item() == 0:
        return 0.0
    dists = torch.norm(pred - gt, dim=2)
    correct = (dists <= R) & mask
    return float(correct.sum().item()) / float(mask.sum().item())


def train_model(
    cfg: HRNetConfig,
    train_samples: List[Tuple[Path, Path, str]],
    val_samples: List[Tuple[Path, Path, str]],
    num_keypoints: int,
    run_id: str,
    root: Path,
    log_path: Path,
) -> Dict[str, Any]:
    """
    Основной цикл обучения. Пишет:
    - models/history/<run_id>/hrnet_best.pth, metrics.json, train_config.yaml, train_log.txt
    - models/current/hrnet_best.pth, quality.json
    - logs/train_hrnet_last.log
    """
    log_file = log_path.open("w", encoding="utf-8")

    def log(msg: str) -> None:
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        line = f"[{ts}] {msg}"
        print(line)
        log_file.write(line + "\n")
        log_file.flush()

    history_dir = root / "models" / "history" / run_id
    history_dir.mkdir(parents=True, exist_ok=True)
    current_dir = root / "models" / "current"
    current_dir.mkdir(parents=True, exist_ok=True)

    # Ветка без torch: честная заглушка, но с корректными файлами метрик
    if torch is None:
        log("PyTorch не установлен. Обучение выполнить нельзя, пишем нулевые метрики и выходим без падения.")
        metrics = {
            "run_id": run_id,
            "n_train": len(train_samples),
            "n_val": len(val_samples),
            "pck_r": 0.0,
            "pck_r_percent": 0.0,
            "R": 0.0,
        }
        quality = {
            "run_id": run_id,
            "pck_r": 0.0,
            "pck_r_percent": 0.0,
            "n_train": len(train_samples),
            "n_val": len(val_samples),
        }
        quality_path = current_dir / "quality.json"
        with quality_path.open("w", encoding="utf-8") as f:
            json.dump(quality, f, indent=2)
        metrics_path = history_dir / "metrics.json"
        with metrics_path.open("w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=2)
        log_file.close()
        history_log = history_dir / "train_log.txt"
        try:
            shutil.copy2(log_path, history_log)
        except Exception:
            pass
        return metrics

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    log(f"Используем устройство: {device}")

    log(
        f"Всего образцов: {len(train_samples) + len(val_samples)} "
        f"(train={len(train_samples)}, val={len(val_samples)})"
    )

    train_ds = LandmarkDataset(train_samples, num_keypoints, cfg, phase="train")
    val_ds = LandmarkDataset(val_samples, num_keypoints, cfg, phase="val")

    train_loader = DataLoader(
        train_ds,
        batch_size=max(1, int(cfg.batch_size)),
        shuffle=True,
        num_workers=0,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=max(1, int(cfg.batch_size)),
        shuffle=False,
        num_workers=0,
    )

    model = SimpleHRNet(num_keypoints=num_keypoints).to(device)
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=float(cfg.learning_rate),
        weight_decay=float(cfg.weight_decay),
    )
    criterion = nn.MSELoss()

    best_pck = 0.0
    best_state: Optional[Dict[str, Any]] = None

    # Радиус для PCK берём как 5% от размера входного квадрата
    R = 0.05 * float(cfg.input_size)

    for epoch in range(int(cfg.max_epochs)):
        model.train()
        running_loss = 0.0
        n_batches = 0
        for batch in train_loader:
            images = batch["image"].to(device)
            keypoints = batch["keypoints"].to(device)

            optimizer.zero_grad()
            outputs = model(images)
            # outputs: (B, K, H, W)
            B, K, H, W = outputs.shape
            target_hm = generate_heatmaps(keypoints, H, W)
            loss = criterion(outputs, target_hm)
            loss.backward()
            optimizer.step()

            running_loss += float(loss.item())
            n_batches += 1

        if n_batches == 0:
            log("Нет батчей для обучения. Останавливаемся.")
            break

        avg_loss = running_loss / n_batches

        # Валидация
        model.eval()
        all_pred = []
        all_gt = []
        with torch.no_grad():
            for batch in val_loader:
                images = batch["image"].to(device)
                keypoints = batch["keypoints"].to(device)
                outputs = model(images)
                pred_kps = heatmaps_to_keypoints(outputs)
                all_pred.append(pred_kps.cpu())
                all_gt.append(keypoints.cpu())
        if all_pred:
            pred_cat = torch.cat(all_pred, dim=0)
            gt_cat = torch.cat(all_gt, dim=0)
            pck = compute_pck_at_r(pred_cat, gt_cat, R)
        else:
            pck = 0.0

        log(f"Эпоха {epoch+1}/{cfg.max_epochs} - loss={avg_loss:.4f}, PCK@R={pck*100:.2f}%")

        if pck >= best_pck:
            best_pck = pck
            best_state = model.state_dict()

        # Если нет валидации – берём последний слепок как лучший и выходим
        if len(val_ds) == 0:
            best_pck = 0.0
            best_state = model.state_dict()
            log("Нет валидационных данных. Используем веса последней эпохи как лучшие.")
            break

    if best_state is None:
        best_state = model.state_dict()

    # Сохраняем модель
    best_model_path = history_dir / "hrnet_best.pth"
    torch.save(best_state, best_model_path)
    torch.save(best_state, current_dir / "hrnet_best.pth")

    metrics = {
        "run_id": run_id,
        "n_train": len(train_ds),
        "n_val": len(val_ds),
        "pck_r": float(best_pck),
        "pck_r_percent": float(best_pck * 100.0),
        "R": R,
    }
    metrics_path = history_dir / "metrics.json"
    with metrics_path.open("w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2)

    quality = {
        "run_id": run_id,
        "pck_r": float(best_pck),
        "pck_r_percent": float(best_pck * 100.0),
        "n_train": len(train_ds),
        "n_val": len(val_ds),
    }
    quality_path = current_dir / "quality.json"
    with quality_path.open("w", encoding="utf-8") as f:
        json.dump(quality, f, indent=2)

    # Сохраняем снимок конфига
    cfg_path_hist = history_dir / "train_config.yaml"
    if yaml is not None:
        with cfg_path_hist.open("w", encoding="utf-8") as f:
            yaml.safe_dump(
                {k: getattr(cfg, k) for k in cfg.__dataclass_fields__.keys()},  # type: ignore[attr-defined]
                f,
                sort_keys=False,
                allow_unicode=True,
            )

    log_file.close()
    # Копируем лог обучения в историю
    history_log = history_dir / "train_log.txt"
    try:
        shutil.copy2(log_path, history_log)
    except Exception:
        pass

    return metrics


def write_datasets_txt(
    root: Path,
    run_id: str,
    train_samples: List[Tuple[Path, Path, str]],
    val_samples: List[Tuple[Path, Path, str]],
) -> None:
    """
    По ТЗ: сохраняем списки датасета datasets/hrnet_train_<run_id>.txt и hrnet_val_<run_id>.txt
    Формат: image_path;csv_path;locality
    """
    datasets_dir = root / "datasets"
    datasets_dir.mkdir(parents=True, exist_ok=True)
    train_txt = datasets_dir / f"hrnet_train_{run_id}.txt"
    val_txt = datasets_dir / f"hrnet_val_{run_id}.txt"

    def _write(path: Path, samples: List[Tuple[Path, Path, str]]) -> None:
        with path.open("w", encoding="utf-8") as f:
            for img_path, csv_path, loc in samples:
                f.write(f"{img_path};{csv_path};{loc}\n")

    _write(train_txt, train_samples)
    _write(val_txt, val_samples)


def main(argv: Optional[List[str]] = None) -> int:
    """
    Точка входа для действия 1) Train / Finetune model on MANUAL localities.
    Никаких новых ключей/режимов не добавляем, только внутренняя реализация.
    """
    argv = list(sys.argv[1:] if argv is None else argv)
    parser = argparse.ArgumentParser(description="Train HRNet model on MANUAL localities")
    # parse_known_args, чтобы не сломаться, если trainer_menu.py что-то передаёт
    parser.add_argument("--dummy", help="Не используется, только для совместимости", default=None)
    args, _unknown = parser.parse_known_args(argv)

    root = get_landmark_root()
    cfg_path = root / "config" / "hrnet_config.yaml"
    cfg = load_yaml_config(cfg_path)

    lm_number = read_lm_number(root)
    if lm_number <= 0:
        print("[ERR] LM_number.txt не найден или содержит неверное значение.")
        return 1

    base_dir = read_last_base(root)
    if base_dir is None:
        print("[ERR] cfg\\last_base.txt не найден или папка с локальностями отсутствует.")
        return 1

    samples = gather_manual_samples(root, base_dir)
    if not samples:
        print("[INFO] MANUAL локальностей с полными PNG+CSV не найдено. Обучать нечего.")
        return 0

    # Один раз тасуем и делим, чтобы split совпадал и для логов, и для обучения
    random.shuffle(samples)
    train_val = float(cfg.train_val_split)
    split_idx = int(len(samples) * train_val)
    train_samples = samples[:split_idx]
    val_samples = samples[split_idx:]

    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    logs_dir = root / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    log_path = logs_dir / "train_hrnet_last.log"

    # По ТЗ: сохраняем списки датасета
    write_datasets_txt(root, run_id, train_samples, val_samples)

    metrics = train_model(cfg, train_samples, val_samples, lm_number, run_id, root, log_path)

    print("==== HRNet training finished ====")
    print(json.dumps(metrics, indent=2, ensure_ascii=False))
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
'@ | Set-Content -Path $trainPath -Encoding UTF8
PS D:\GM\tools\2_Landmarking_v1.0> # --- 2) Перезаписываем scripts\infer_hrnet.py ---
PS D:\GM\tools\2_Landmarking_v1.0> $inferPath = "scripts\infer_hrnet.py"
PS D:\GM\tools\2_Landmarking_v1.0> @'
from __future__ import annotations

import argparse
import csv
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

import numpy as np
from PIL import Image

try:
    import torch
    from torch import nn
except ImportError:  # pragma: no cover
    torch = None
    nn = None

try:
    import yaml
except ImportError:  # pragma: no cover
    yaml = None


@dataclass
class HRNetConfig:
    # Те же поля, что и в train_hrnet.py
    model_type: str = "hrnet_w32"
    input_size: int = 256
    resize_mode: str = "resize"
    keep_aspect_ratio: bool = True
    batch_size: int = 8
    learning_rate: float = 5e-4
    max_epochs: int = 100
    train_val_split: float = 0.9
    flip_augmentation: bool = True
    rotation_augmentation_deg: float = 15.0
    scale_augmentation: float = 0.3
    weight_decay: float = 1e-4


def get_landmark_root() -> Path:
    return Path(__file__).resolve().parent.parent


def load_yaml_config(cfg_path: Path) -> HRNetConfig:
    cfg = HRNetConfig()
    if yaml is None or not cfg_path.is_file():
        return cfg
    with cfg_path.open("r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    for field in cfg.__dataclass_fields__.keys():  # type: ignore[attr-defined]
        if field in data:
            setattr(cfg, field, data[field])
    return cfg


def read_lm_number(root: Path) -> int:
    lm_file = root / "LM_number.txt"
    try:
        txt = lm_file.read_text(encoding="utf-8").strip()
        return int(txt)
    except Exception:
        return 0


def read_last_base(root: Path) -> Optional[Path]:
    cfg_file = root / "cfg" / "last_base.txt"
    if not cfg_file.is_file():
        return None
    txt = cfg_file.read_text(encoding="utf-8").strip()
    if not txt:
        return None
    p = Path(txt)
    return p if p.is_dir() else None


def _resize_and_pad(img: Image.Image, cfg: HRNetConfig) -> Tuple[Image.Image, float, float, float]:
    """
    Та же логика ресайза, что и в train_hrnet.py: даунскейл + паддинг.
    Возвращаем:
    - изображение,
    - scale (во сколько раз уменьшили),
    - offset_x, offset_y (сколько пикселей добавили слева/сверху).
    """
    input_size = int(cfg.input_size)
    if input_size <= 0:
        w, h = img.size
        return img, 1.0, 0.0, 0.0

    w, h = img.size
    if max(w, h) == 0:
        return img, 1.0, 0.0, 0.0

    scale = min(1.0, float(input_size) / float(max(w, h)))
    new_w = int(round(w * scale))
    new_h = int(round(h * scale))
    img_resized = img
    if scale != 1.0:
        img_resized = img.resize((new_w, new_h), Image.BILINEAR)

    canvas = Image.new("RGB", (input_size, input_size), (0, 0, 0))
    offset_x = (input_size - new_w) // 2
    offset_y = (input_size - new_h) // 2
    canvas.paste(img_resized, (offset_x, offset_y))
    return canvas, scale, float(offset_x), float(offset_y)


class SimpleHRNet(nn.Module):
    """
    Точно такой же бэкбон, как в train_hrnet.py (SimpleHRNet),
    чтобы успешно загрузить hrnet_best.pth.
    """

    def __init__(self, num_keypoints: int) -> None:
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        blocks = []
        in_channels = 64
        for _ in range(3):
            block = nn.Sequential(
                nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),
                nn.BatchNorm2d(in_channels),
                nn.ReLU(inplace=True),
                nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),
                nn.BatchNorm2d(in_channels),
            )
            blocks.append(block)
        self.blocks = nn.ModuleList(blocks)
        self.relu = nn.ReLU(inplace=True)
        self.head = nn.Conv2d(64, num_keypoints, kernel_size=1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.stem(x)
        for block in self.blocks:
            residual = x
            out = block(x)
            x = self.relu(out + residual)
        heatmaps = self.head(x)
        return heatmaps


def heatmaps_to_keypoints(heatmaps: torch.Tensor) -> torch.Tensor:
    """
    Из теплокарт получаем координаты максимумов.
    """
    B, K, H, W = heatmaps.shape
    heatmaps_reshaped = heatmaps.view(B, K, -1)
    idx = heatmaps_reshaped.argmax(dim=2)  # (B, K)
    ys = (idx // W).float()
    xs = (idx % W).float()
    kps = torch.stack([xs, ys], dim=2)
    return kps


def infer_for_locality(
    root: Path,
    base_dir: Path,
    locality: str,
    cfg: HRNetConfig,
    num_keypoints: int,
    model_path: Path,
    log_fn,
) -> None:
    """
    Автолейблинг одной локальности: пробегаем все PNG и сохраняем CSV с (x,y).
    """
    loc_dir = base_dir / locality / "png"
    if not loc_dir.is_dir():
        log_fn(f"[WARN] Не найдена папка локальности: {loc_dir}")
        return

    if torch is None:
        log_fn("[ERR] PyTorch не установлен. Инференс невозможен.")
        return

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    log_fn(f"[INFO] Устройство: {device} для локальности {locality}")

    model = SimpleHRNet(num_keypoints=num_keypoints)
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.to(device)
    model.eval()

    img_paths = sorted(loc_dir.glob("*.png"))
    if not img_paths:
        log_fn(f"[INFO] В {loc_dir} нет PNG-изображений.")
        return

    for img_path in img_paths:
        img = Image.open(img_path).convert("RGB")
        img_resized, scale, offset_x, offset_y = _resize_and_pad(img, cfg)

        np_img = np.asarray(img_resized, dtype=np.float32) / 255.0
        np_img = np.transpose(np_img, (2, 0, 1))  # CHW
        tensor = torch.from_numpy(np_img).unsqueeze(0).to(device)

        with torch.no_grad():
            heatmaps = model(tensor)
            kps_resized = heatmaps_to_keypoints(heatmaps)[0]  # (K, 2)

        # Возвращаемся к координатам оригинального изображения
        if scale > 0:
            kps_original = kps_resized.clone()
            # Убираем паддинг
            kps_original[:, 0] -= offset_x
            kps_original[:, 1] -= offset_y
            # Убираем масштабирование
            kps_original /= scale
        else:
            kps_original = kps_resized

        # Гарантируем ровно num_keypoints строк
        if kps_original.shape[0] < num_keypoints:
            pad = torch.zeros((num_keypoints - kps_original.shape[0], 2), dtype=kps_original.dtype)
            kps_original = torch.cat([kps_original, pad], dim=0)
        elif kps_original.shape[0] > num_keypoints:
            kps_original = kps_original[:num_keypoints]

        out_csv = img_path.with_suffix(".csv")
        with out_csv.open("w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["x", "y"])
            for i in range(num_keypoints):
                x = float(kps_original[i, 0].item())
                y = float(kps_original[i, 1].item())
                writer.writerow([x, y])

        log_fn(f"[OK] CSV сохранён для {img_path.name}")


def main(argv: Optional[List[str]] = None) -> int:
    """
    Точка входа для действия 2) Autolabel locality with current model.
    Варианты вызова:
    - без аргументов: берём base_dir из cfg\\last_base.txt и все локальности из localities_status.csv, у которых есть png-папка;
    - с аргументами: если первый аргумент — существующая папка, считаем её base_dir, а остальное — имена локальностей;
      иначе все аргументы считаем локальностями, а base_dir берём из cfg\\last_base.txt.
    """
    argv = list(sys.argv[1:] if argv is None else argv)
    parser = argparse.ArgumentParser(description="Autolabel locality with current HRNet model")
    parser.add_argument(
        "args",
        nargs="*",
        help="Необязательный base_dir, затем имена локальностей.",
    )
    args = parser.parse_args(argv)

    root = get_landmark_root()
    cfg_path = root / "config" / "hrnet_config.yaml"
    cfg = load_yaml_config(cfg_path)

    lm_number = read_lm_number(root)
    if lm_number <= 0:
        print("[ERR] LM_number.txt не найден или содержит неверное значение.")
        return 1

    base_dir: Optional[Path] = None
    localities: List[str] = []

    # Если первый аргумент — существующая директория, считаем её base_dir
    if args.args:
        first = Path(args.args[0])
        if first.is_dir():
            base_dir = first
            localities = [a for a in args.args[1:] if a.strip()]
        else:
            localities = [a for a in args.args if a.strip()]

    if base_dir is None:
        base_dir = read_last_base(root)
    if base_dir is None:
        print("[ERR] Базовая папка локальностей не определена (нет cfg\\last_base.txt).")
        return 1

    if not localities:
        # Fallback: все локальности, которые есть в localities_status.csv и имеют подпапку png
        status_file = root / "status" / "localities_status.csv"
        if status_file.is_file():
            with status_file.open("r", encoding="utf-8", newline="") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    loc = row.get("locality", "").strip()
                    if not loc:
                        continue
                    loc_dir = base_dir / loc / "png"
                    if loc_dir.is_dir():
                        localities.append(loc)
        localities = sorted(set(localities))

    logs_dir = root / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    log_path = logs_dir / "infer_hrnet_last.log"
    log_file = log_path.open("w", encoding="utf-8")

    def log(msg: str) -> None:
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        line = f"[{ts}] {msg}"
        print(line)
        log_file.write(line + "\n")
        log_file.flush()

    model_path = root / "models" / "current" / "hrnet_best.pth"
    if not model_path.is_file():
        log("[ERR] models/current/hrnet_best.pth не найден. Сначала нужно обучить модель (действие 1).")
        log_file.close()
        return 1

    log(f"[INFO] Базовая папка: {base_dir}")
    log(f"[INFO] Локальности для автолейблинга: {localities}")

    for loc in localities:
        infer_for_locality(root, base_dir, loc, cfg, lm_number, model_path, log)

    log_file.close()
    print("[INFO] Autolabel finished.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
'@ | Set-Content -Path $inferPath -Encoding UTF8
PS D:\GM\tools\2_Landmarking_v1.0> # --- 3) Быстрая проверка синтаксиса Python (без запуска обучения) ---
PS D:\GM\tools\2_Landmarking_v1.0> & $py -m compileall $trainPath, $inferPath

PS D:\GM\tools\2_Landmarking_v1.0> Stop-Transcript
**********************
Конец записи протокола Windows PowerShell
Время окончания: 20251115165057
**********************
